- Last time: showed that the dual of the max flow LP is the min cut LP
- **Complementary slackness:** a variable and its dual condition cannot both be slack at the same time
## Min cost flow
The max flow LP formulation seeks to maximize $x_{ts}$
- To turn it into a min cost flow optimization, we minimize $-x_{ts} \cdot C + \sum x_{vw} c _{vw}$, where $C$ Is some large positive constant.

Let $x^*$, $y^*$ be optima for the primal & dual problems of min cost flow. What do we get from complementary slackness?
- Suppose $x^*_{vw} < u_{vw}$ â€” that is, the edge $(v, w)$ is not saturated. This is a slack constraint on the primal.
- Every constraint corresponds to a variable in the dual, so the dual variable $y_{vw}$ is tight (equal to zero).
- Since we have $y_{vw} = \min(\tilde{c}_{vw}, 0)$, we know the reduced cost is nonnegative.
- Conversely, if the reduced cost is negative, i.e. $\tilde{c}_{vw} < 0$, then the primal constraint is tight (i.e. edge is saturated).
- If the reduced cost is positive, then we have a tight constraint $y_{vw} \le \tilde{c}_{vw}$ and the corresponding variable is tight on *its* constraint (i.e. $x_{vw} = 0$)

Question: [**IS MIN COST FLOW "AS EASY" AS SHORTEST PATHS?**]
## Finally: algorithms for LP
- Simplex algorithm (1940s by Dantzig)
	- Works great in practice (except when it doesn't !! because it's not polynomial)
- Ellipsoid algorithm (1970s)
	- Polynomial time, "like $n^6$ or something"
	- Theory ramifications are H U G E
- Interior point algorithms (1980s)
	- Polynomial time
	- Works well in practice
### Simplex
Local search algorithm: starts at some vertex and looks for a better vertex

Physics intuition: ball rolls down various "gutters" on the inside of the polytope until it reaches the optimum

Standard form LP, restructured:
- $\min cx$ given $Ax = b$ and $x \ge 0$.

WLOG, $A$ has full row rank (no linearly dependent rows). We can do this b/c start with a basis of rows $a_1, \dots, a_k$. If $a_\ell$ is a linear combination of the basis, $a_\ell x$ is a linear combination of the $a_i x$, which is a linear combination of the elements of $b$. So $b_\ell$ a linear combination of the appropriate $b_i$ ... thus we are automatically good for this row.

[**QUESTION:**] why is it true that $\sum \lambda_i b_i = b_\ell$?
- Answer: otherwise we'd have an infeasible system (no solution to $Ax = b$)

Vertices: $m$ equality constraints are tight and $n-m$ of the $x_i \ge 0$ constraints are tight (i..e $x_i = 0$).
- Together, all of these constraints must form a basis
Let's write the matrix of tight constraints
- First $m$ rows correspond to equality constraints, when multiplied with $x$ produces $b$
- Last $n-m$ constraints just set the $x_i$ equal to zero, they occupy the lower left $(n-m) \times (n-m)$
- $n$ variables and $n$ constraints ($m$ are equality, $n - m$ are tight zeros)
- Last $m$ columns are linearly independent, which is true because $A$ has full row rank

Thus: $x$ is a vertex iff
- $Ax = b$
- $m$ linearly independent columns of $A$ include all $x_j > 0$ (because the other $n-m$ are zero)
This set of linearly independent columns is called a **basis**. The set of corresponding $x_j$ are called **basic**. The other $x_j$ (those that equal zero) are **nonbasic.**

Let $B$ be the set of basic variables. Let $N$ be the set of nonbasic variables.
- Note: Given $B$, we can compute $x$ because the rest are zero and deriving the original is just computing an inverse of $B$.
	- Formally:
	  $$ (A_N A_B) \dbinom{x_N}{x_B} = b. $$
	  Recall that $x_N$ is zero, so really we just need $A_B x_B = b$.
### The algorithm
Start at a basis (we will now use "basis" interchangeably with "vertex")

Claim:
- Start at a basis and keep moving to a better vertex
- If we can't, then we are optimal

*Proof.*
- Everything we discuss is now relative to our current basis $x, B$
- Rewrite LP:
	- min $c_B x_B + c_N x_N$
	- subject to $A_B x_B + A_N x_N = b$
	- and $x \ge 0$
	- Manipulate:
		- $x_B = A_B^{-1} (b - A_N x_N)$
		- True for *any* feasible $x$ (not only our current vertex, setting $B$ and $N$ based on our $x$)
	- Plug in to objective:
		- $cx = cx_B + c_N x_N = c_B A_B^{-1} (b - A_N x_N) + c_N x_N$
	- Our constant term... manipulate to get
		- $c_B A_B^{-1} b + (-c_B A_B^{-1} A_N + c_N)x_N$
	- Ignore the constant, rewrite the stuff in the parentheses to be $\tilde{c}_N$. So we want to optimize
		- $\tilde{c}_N x_N$.
	- This hasn't changed the problem, but makes some things apparent. In particular, $\tilde{c}_N$ is purely a function of $N$, so once we know $N$, we can easily optimize !!!
	- Shorthand: $\tilde{c} = \tilde{c}_N$
	- Suppose all $\tilde{c}_j \ge 0$. Then $x_N$ should be all zero to minimize $\tilde{c}_N x$. We can't improve on this because any other vertex has objective at least $c_B A_B^{-1} b$ and is **not better**.
	- On the other hand, if some $\tilde{c}_j < 0$, then we could make $x_j$ positive and this makes the objective better. Doing this increase changes $x_B$. We can keep increasing $x_j$ until something in the $x_B$ hits zero, i.e. another constraint becomes tight.
	- "Figuring out which of the $x_B$ hits zero first is some straightforward linear algebra"
		- [**how**]
	- This is called a **pivot step**
- Notice that if we increase some $x_j$ in the nonbasic (zero) set becomes slack, it moves into the basic set. Meanwhile, some $x_i$ that was in the basic set becomes nonbasic (because it's now zero).
	- After each pivot step, the reduced costs change based on the new $N$, $B$

Some things to worry about:
- To run simplex, we need an initial vertex. This is the LP feasibility problem ,,,,
- This algorithm terminates in a finite number of steps...right?
	- Maybe all the $x_j$ where $\tilde{c}_j < 0$ is already tight ðŸ¤”
	- So we swap a tight $x_j$ for another already tight $x_i$, meaning we don't really pivot at all 
	- It is possible we swap $x_i$ and $x_j$ again, i.e. cycle, which is bad
	- **Can** prove that non-cycling pivot rules exist, i.e. there are rules that guarantee we never hit a basis that we've seen already
		- Lexicographical ordering works lmao
		- "perturbation"

How long does it take for simplex to terminate?
- There are $\binom{n}{m}$ vertices, so it is possible we are too slow in theory
- Klee-Minty Cube: a polytope where simplex visits every single vertex
- At least maybe the diameter is small?
	- Wouldn't guarantee a fast simplex algorithm because the shortest path doesn't consistently improve the objective
	- Conjecture: **Hirsch** (1957) â€” diameter of a polytope is at most $m + n$
	- Disproved in 2010 by Santos
		- Proved that diameter is at least $(1 + \epsilon)(m + n)$
	- Kalai - Kleitman (1972): max diameter is $m^{\log n}$
		- Used randomization

Right now
- There is a linear-time LP algorithm for fixed $n$ (Seidel, 1990s)
- 