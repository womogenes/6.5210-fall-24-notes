## Simplex, finished up
- "reduced costs" $\tilde{c}_N = c_N - c_B A_B^{-1} A_N$ assign new objective coefficient to the non-basic variables (zero at the current point)
- If $\tilde{c}_N \ge 0$, there's nothing we can change to make the objective better
- If $\tilde{c}_j < 0$, we can pivot $x_j$ to make it better !!

Suppose we are at an optimum, i.e. $\tilde{c}_N \ge 0$. Define
$$y = c_B A_B^{-1}. $$
This means
$$ \tilde{c_N} = c_N - y A_N \ge 0. $$
Conclusion:
$$ y A_N \le c_N. $$
From the defn. of $y$, $yA_B = c_B$. Conclude that $yA \le c$. This means $y$ is dual-feasible!

Also, $yb = c_B A_B^{-1} b = c_B x_B$. So really $cx = c_B x_B + c_N x_N = c_B x_B$. By strong duality, $yb = cx$, so $y$ is optimal.

We can keep track of $yb - cx$ through the course of Simplex iterations and stop when it gets to zero.
## Poly-time LP algorithms
### Ellipsoid algorithm
Developed in 1979 by Khachiyan
- Find a feasible point in a polytope.
One way to think about this: binary search

We know feasibility is as hard as optimality. Binary search for a feasible point.
- Take a hyperplane: is there a side that has **no** feasible points? If so, we can rule out that side.

Main loop:
- Algorithm offers a **candidate point**
- If feasible, we are done
- If not feasible:
	- Does not satisfy some constraint.
	- Call this constraint a **separating hyperplane**.
- Maintain a big ellipsoid
	- Ask about the center of the ellipsoid
	- As long as the center is not feasible, shrink the ellipsoid
- Fundamental condition: you can always find an ellipsoid with less volume that still contains half the ellipsoid

Ellipsoid definition: $E(D, z)$ where $D$ is the radius matrix
$$ E(D, z) = \{ x \mid (x - z)^T D^{-1} (x - z) \le 1 \}$$
and $z$ is the center. Required: $D$ is a positive semidefinite matrix $BB^T$ for some invertible $B$. Example: $E(I, z)$ is the unit hypersphere

In general, $E(D, z)$ is an affine transformation of the unit sphere $x \rightarrow Bx + z$.
- Thus, what we can do is solve the "find smaller ellipsoid that covers half" for a **sphere** (it generalizes)

**Bounds**
- We must consider starting and ending ellipsoid size
- Starting ellipsoid size
	- Recall that all vertices have coordinates of size $n^{o(1)}$ bits
	- Can draw a sphere with radius having $n^{o(1)}$ bits containing all such points.
	- Only takes $n^{o(1)}$ "halvings" of volume to reduce the volume to 2
- Ending ellipsoid size
	- Feasible set might not be full-dimensional --> volume 0
	- Bump constraints $Ax \le b$ up to $Ax \le b + \varepsilon$

Fun fact:
- As long as we have a **"separation oracle,"** we can proceed through the steps of the ellipsoid algorithm. The separation oracle just gives us a separating hyperplane (violated constraint) at every step.
- Ellipsoid works for LP problems that are too big to write down

There are many problems in TCS where you develop a separation oracle to solve it, because that gives you optimization.
### Interior point method
Motivation: physics
- Simplex sort of lets a ball roll down into the well, but a mess happens every time we hit a corner
- So make the ball iron and put magnets behind every vertex that repels the ball
- Eventually it will drift down to the optimum
- "Barrier methods"
	- Basically turn all the constraints into a nonlinear potential function, which turns the problem into an unconstrainted optimization problem
	- Gradient descent!
	- Good potential function (standard form):
	  $$ cx - \mu \left(\sum \log x_i \right) $$
	  This potential function seeks to minimize $cx$ but doesn't let $x_i$ get too close to zero. Gradient:
	  $$ \nabla G(x) = c - \sum \frac{\mu}{x_i} $$
	  You can prove that there is a suitable step size such that after a while, the point gets close to the optimal vertex.

Given $\mu$, $G_\mu(x)$ has an optimum. Varying $\mu$ from $\infty$ to $0$ traces out a polytope. It start at the center and ends at OPT. This is called the "central path" of the optimization problem.
- These are called **"path following"/"path correcting"** algorithms

